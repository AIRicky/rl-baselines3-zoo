# Tuned
HalfCheetahBulletEnv-v0:
  env_wrapper: utils.wrappers.TimeFeatureWrapper
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  gamma: 0.98
  buffer_size: 200000
  learning_starts: 10000
  noise_type: 'normal'
  noise_std: 0.1
  gradient_steps: -1
  n_episodes_rollout: 1
  learning_rate: !!float 1e-3
  policy_kwargs: "dict(net_arch=[400, 300])"
  use_sde: False

AntBulletEnv-v0:
  env_wrapper: utils.wrappers.TimeFeatureWrapper
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  gamma: 0.98
  buffer_size: 200000
  learning_starts: 10000
  noise_type: 'normal'
  noise_std: 0.1
  gradient_steps: -1
  n_episodes_rollout: 1
  learning_rate: !!float 1e-3
  policy_kwargs: "dict(net_arch=[400, 300])"
  use_sde: False

HopperBulletEnv-v0:
  env_wrapper: utils.wrappers.TimeFeatureWrapper
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  gamma: 0.98
  buffer_size: 200000
  learning_starts: 10000
  noise_type: 'normal'
  noise_std: 0.1
  gradient_steps: -1
  n_episodes_rollout: 1
  learning_rate: !!float 1e-3
  policy_kwargs: "dict(net_arch=[400, 300])"
  use_sde: False

Walker2DBulletEnv-v0:
  env_wrapper: utils.wrappers.TimeFeatureWrapper
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  gamma: 0.98
  buffer_size: 200000
  learning_starts: 10000
  noise_type: 'normal'
  noise_std: 0.1
  gradient_steps: -1
  n_episodes_rollout: 1
  learning_rate: !!float 1e-3
  policy_kwargs: "dict(net_arch=[400, 300])"
  use_sde: False
